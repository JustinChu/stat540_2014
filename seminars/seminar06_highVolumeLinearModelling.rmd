% Seminar 6: Fitting and interpretting linear models (high volume)
% Jenny Bryan
% 2013-02-06

In the spirit of "teaching you to fish", I'll be providing less code for things you've done before. As always, you are also strongly encouraged to retain and develop your R code in a script.

## Preliminaries

If you haven't done so already, install `limma` (I'm copying [instructions found here](http://bioinf.wehi.edu.au/limma/)):

```{r, eval=FALSE}
source("http://www.bioconductor.org/biocLite.R")
biocLite("limma")
biocLite("statmod")
```
Load the `limma` and/or `lattice` package, if you need to:
```{r}
library(limma)
library(lattice)
```

Load the `photoRec` dataset:

> Remember you may need to edit the file paths below, to reflect your working directory and local file storage choices.

```{r}
prDat <- read.table("../data/photoRec/GSE4051_data.txt") # the whole enchilada
str(prDat, max.level = 0)
load("../data/photoRec/GSE4051_design.robj") # load exp design as 'prDes'
str(prDes)
```

You might want to use the functions you wrote last week to extract and stripplot excerpts from the `photoRec` dataset. If you stored the code defining those functions cleanly in a script, you could make them available now by using the `source()` function.

```{r, echo=FALSE}
prepareData <- function(myGenes) {
    miniDat <- t(wtDat[myGenes, ])
    miniDat <- data.frame(gExp = as.vector(miniDat),
                          gene = factor(rep(colnames(miniDat), each =
                          nrow(miniDat)), levels = colnames(miniDat)))
    miniDat <- suppressWarnings(data.frame(wtDes, miniDat))
    miniDat
}
stripplotIt <- function(myData, ...) {
    stripplot(gExp ~ devStage | gene, myData,
              jitter.data = TRUE,
              auto.key = TRUE, type = c('p', 'a'), grid = TRUE, ...)
}
```

## The difficulty in estimating gene-wise variance

The `lmFit` function from `limma` is arguably your main workhorse function for fitting a common linear model to the data for a very large number of genes. It has at least two strengths to recommend it:

  * It does this in a computationally efficient way, i.e. better than you writing a top-level `for()` loop and probably even better than pursuing an `apply()`-type strategy.
  * It borrows strength across the large number of genes (= datasets) to moderate the gene-wise estimate of error variance.
  
Before we dive in and start using `limma` with the `photoRec` dataset, let's do a small simulation to illustrate how lousy variance estimates can be when the number of samples is small.

Let's simulate data for 1000 genes. For each we gene, we get 3 observations from a normal distribution with mean 0 and variance 1. We generate the data for each gene independent of the others.

```{r}
m <- 1000
n <- 3
x <- matrix(rnorm(m * n), nrow = m)
```
Let's take the observed gene-wise variances. Yes, folks, we are estimating with variance with samples of size 3. People do this all the time -- remember the video? We inspect them a bit numerically and graphically.
```{r}
obsVars <- apply(x, 1, var)
summary(obsVars)
mean(obsVars < 1/3)
densityplot(~ obsVars, n = 200)
```
Notice how many of the observed variances are freakishly small (and freakishly large!), even though they are indeed equal to 1 "on average". For example, we see that at least a quarter of the genes appear to exhibit a sample variance that is less than one-third the true variance. This can wreak havoc with statistical inference, such as t-statistics. This is what `limma` -- or the statistical methods it embodies, actually -- is designed to combat.

Optional take-home exercise: Make the above simulation more realistic with two (or more) groups, different data-generating means and group differences, different data-generating gene-wise variances, etc.

## Fit a linear model: explain gene expression in the wild type mice as a function of developmental stage (one-way ANOVA)

Let's just work with the wild type data.

```{r}
wtDes <- subset(prDes, gType == "wt")
str(wtDes)
wtDat <- subset(prDat, select = prDes$gType == "wt")
str(wtDat, max.level = 0)
```
Before we can use `limma` we must make our design matrix. Let's accept the default "ref + treatment effects" scheme for handling the `devStage` factor. I encourage you to inspect the design matrix and confirm it's what you expect.
```{r}
wtDesMat <- model.matrix(~ devStage, wtDes)
str(wtDesMat)
```
Now we will fit the model, for all probes at once, and use `eBayes()` to moderate the estimated error variances:
```{r}
wtFit <- lmFit(wtDat, wtDesMat)
wtEbFit <- eBayes(wtFit)
```
The first thing we might ask is "which genes show differential expression over the course of development"? This can be addressed with an overall F test for the model. In the language used in lecture, we will compare a "big" model to a "small" model, where the "big" model includes a mean parameter (or effect) for each level of `devStage` and the "small" model includes a single mean parameter, e.g. an intercept. You might expect this to be the F test performed by `topTable()` by default, i.e. when no specific coefficients or contrasts are given to the `coef` argument ...
```{r}
topTable(wtEbFit)
```
You'll see that, by default, `topTable()` reports the top 10 hits. But let's take more care and specify explicitly the coefficients we want to test for equality with zero. Recall that one can specify these by number but I recommend doing this by name.

```{r, eval=FALSE}
## these calls will work but have drawbacks
topTable(wtEbFit, coef = 2:5) # cryptic! error-prone!
topTable(wtEbFit,
         coef = c("devStageP2", "devStageP6",
                  "devStageP10", "devStage4_weeks")) # a drag to type
```

```{r}
colnames(coef(wtEbFit)) # remind yourself of the coef names
(dsHits <- topTable(wtEbFit,
                    coef = grep("devStage", colnames(coef(wtEbFit)))))
```

You will notice that these are __not__ the same hits we got with our first call to `topTable()`. Compare, e.g., the Affy IDs for the top hits and/or look at the typical F statistic magnitudes. And so we learn that you really must use the `coef` argument (or a contrasts workflow in more complicated settings) to explicitly define __what you regard as a hit__.

Use the hit list you stored above and your functions for extracting and plotting data to produce this plot for hits 3, 6, and 9 on the list.

```{r, echo=FALSE}
stripplotIt(prepareData(dsHits$ID[c(3, 6, 9)]))
```

Does it look plausible to you that -- using only wild type data -- these probes show the most compelling evidence for expression change over development? Note: I have redefined my data extraction and plotting functions to include only the wild type data. You can do that or not, as long as you can remember that all of today's models only work with wild type data.

Optional exercise: use `lm()` on one or all 3 of these probes and check if the F stats and p-values are similar. Don't expect exact equality because you must remember that `limma` has moderated the estimated error variance.

## Be the boss of `topTable()`

You need to learn to take control of `topTable()` by using various arguments to get the hits you want in the order you want. Furthermore, you should familiarize yourself with the output it returns, so you are comfortable extracting the output that you need.

How many probes have Benjamini-Hochberg ("BH") adjusted p-values for the F test conducted above that are less than 1e-05?
```{r, echo=FALSE}
cutoff <- 1e-05
dsHits <- topTable(wtEbFit,
                   coef = grep("devStage", colnames(coef(wtEbFit))),
                   p.value = cutoff, n = Inf)
numBHhits <- nrow(dsHits)
```
My answer: `r numBHhits` probes.

What is the 63rd hit on this list? Provide it's Affy ID, F statistic, BH adjusted p-value, and the estimated effect for developmental stage "P6" __in that order__. Here's what I get:
```{r, echo=FALSE}
dsHits[63, c("F", "adj.P.Val", "devStageP6")]
```

Consider the effects associated with developmental stages P2 and P10. Scatterplot the t statistics for the test that the P2 effect is zero against that for P10. Ideally this plot would be a high-volume scatterplot, have an aspect ratio of 1 and common axes, but don't sweat it too much if you can't do all of that on the spot. Here's what I get:

```{r, echo=FALSE}
P2Hits <- topTable(wtEbFit, coef = "devStageP2", n = Inf, sort = "none")
P10Hits <- topTable(wtEbFit, coef = "devStageP10", n = Inf, sort = "none")
xyplot(P10Hits$t ~ P2Hits$t, aspect = 1,
       xlab = "p-value for P2 effect",
       ylab = "p-value for P10 effect",
       xlim = c(-20, 16), ylim = c(-20, 16),
       panel = function(x, y, ...) {
         panel.smoothScatter(x, y, nbin = 100, ...)
         panel.abline(a = 0, b = 1, col = "orange")
         })
```

Create a densityplot of the associated p-values, so you can get a sense of which developmental stage, P2 or P10, is more clearly distinguished from baseline E16.

```{r, echo=FALSE}
densityplot(~ P10Hits$adj.P.Val + P2Hits$adj.P.Val, auto.key = TRUE, plot.points = FALSE)
```

Is this what you'd expect?

If you require a BH adjusted p-value less than 1e-03, how many hits do you get for P2? How many for P10? How much overlap is there?
```{r, echo=FALSE, message=FALSE}
cutoff <- 1e-03
foo <- data.frame(P2 = P2Hits$adj.P.Val < cutoff,
                  P10 = P10Hits$adj.P.Val < cutoff)
addmargins(with(foo, table(P2, P10)))
```
I get 53 hits for P2, 747 for P10, with an overlap of 52.

Now just focus on the P10 effect. Create a scatterplot matrix of raw p-values, BH adjusted p-values, and BY p-values.

```{r, echo=FALSE, message=FALSE}
P10pVals <- data.frame(raw = P10Hits$P.Value,
                       BH = P10Hits$adj.P.Val,
                       BY = p.adjust(P10Hits$P.Value, method = "BY"))
splom(P10pVals,
      panel = function(x, y, ... ) {
          panel.xyplot(x, y, pch = ".", ...)
          panel.abline(a = 0, b = 1, col = "orange")
      })
```

Is the relationship between raw and BH p-values what you expect? I'm not sure what to say about the BY p-values. I just wanted us to try at least one different method of p-value adjustment.

## Perform inference for some contrasts

Let's try to distinguish genes that have stable expression at the last three developmental stages (P6, P10, and 4_weeks) from those that do not. If expression doesn't change from P6 to P10 to 4_weeks, then the effects for all 3 of those developmental stages should be the same. That means that the difference between the P10 and P6 effects is zero and ditto for the difference between 4_weeks effect and P10 (or P6, for that matter). Let's form these contrasts.
```{r}
colnames(wtDesMat)
(cont.matrix <- makeContrasts(
    P10VsP6 = devStageP10 - devStageP6,
    fourweeksVsP10 = devStage4_weeks - devStageP10,
    levels = wtDesMat))
wtFitCont <- contrasts.fit(wtFit, cont.matrix)
wtEbFitCont <- eBayes(wtFitCont)
```
What does `topTable()` do with our contrasts?
```{r}
topTable(wtEbFitCont)
```
The top hits are probes where there is big change from P6 to P10, from P10 to 4_weeks, or both. Let's check that by plotting the data from the top 4 hits.

```{r, echo=FALSE}
foo <- topTable(wtEbFitCont)
stripplotIt(prepareData(foo$ID[1:4]))
```

So far, so good. These 4 probes show little expression change from P6 to P10 and a strong increase from P10 to 4_weeks. I would like to find some where there's a change in each case but perhaps in opposite direction. Let's press on.

Let's use `decideTests()` to adjust the p-values for both contrasts globally, i.e. all together and then threshhold them at a cutoff of 1e-04.
```{r}
cutoff <- 1e-04
wtResCont <- decideTests(wtEbFitCont, p.value = cutoff, method = "global")
summary(wtResCont)
```
We see there are 4 probes that go down from P6 to P10 and no hits going the other way. There are 8 probes that go down from P10 to 4_weeks and 46 going the other way. Let's try to pull out various hits and plot their data.

Here are the 4 that decline from P6 to P10.
```{r}
(hits1 <- rownames(prDat)[which(wtResCont[, "P10VsP6"] < 0)])
stripplotIt(prepareData(hits1))
```

Here are 4 of the 8 that decline from P10 to 4_weeks.
```{r}
(hits2 <- rownames(prDat)[which(wtResCont[, "fourweeksVsP10"] < 0)])
stripplotIt(prepareData(hits2[1:4]))
```

Is there any overlap between these probes?
```{r}
intersect(hits1, hits2)
```
Apparently not.

Here are 4 of the 46 that increase from P10 to 4_weeks.

```{r}
(hits3 <- rownames(prDat)[which(wtResCont[, "fourweeksVsP10"] > 0)])
stripplotIt(prepareData(hits3[1:4]))
```

Is there any overlap between these probes and the previous "down" hits?

```{r}
intersect(hits1, hits3)
intersect(hits2, hits3)
```

That's disappointing. If I revisit this workflow but make the p-value cutoff less stringent, maybe I can find the gene expression profile I'm looking for.

```{r}
cutoff <- 1e-02
nHits <- 8
wtResCont <- decideTests(wtEbFitCont,p.value = cutoff, method = "global")
summary(wtResCont)
hits1 <- rownames(prDat)[which(wtResCont[, "P10VsP6"] < 0)]
stripplotIt(prepareData(hits1[1:nHits]))
hits2 <- rownames(prDat)[which(wtResCont[, "fourweeksVsP10"] < 0)]
stripplotIt(prepareData(hits2[1:nHits]))
hits3 <- rownames(prDat)[which(wtResCont[, "P10VsP6"] > 0)]
stripplotIt(prepareData(hits3[1:nHits]))
hits4 <- rownames(prDat)[which(wtResCont[, "fourweeksVsP10"] > 0)]
stripplotIt(prepareData(hits4[1:nHits]))
vennDiagram(wtResCont)
hits5 <- rownames(prDat)[which(wtResCont[, "P10VsP6"] != 0 &
                                  wtResCont[, "fourweeksVsP10"] != 0)]
stripplotIt(prepareData(hits5))
hits6 <- rownames(prDat)[which(wtResCont[, "P10VsP6"] > 0 &
                                  wtResCont[, "fourweeksVsP10"] < 0)]
stripplotIt(prepareData(hits6))
```

At last, I succeed!

Take-home exercise: See if you can find one or more probes that have some expression changes up to P6 and then hold steady all the way to 4_weeks. Here's some I found.

```{r, echo=FALSE}
lateStuff <- topTable(wtEbFitCont, n = Inf, sort = "none")
earlyStuff <- topTable(wtEbFit, coef = c("devStageP2", "devStageP6"),
                       n = Inf, sort = "none")
pVals <-
  data.frame(earlyStuff = earlyStuff$adj.P.Val,
             lateStuff = lateStuff$adj.P.Val)
#xyplot(lateStuff ~ earlyStuff, pVals)
discHits <- with(pVals,
     which(earlyStuff < quantile(earlyStuff, probs = 0.05) &
             lateStuff > quantile(lateStuff, probs = 0.95)))
#length(discHits)
set.seed(123)
stripplotIt(prepareData(miniDat <- sample(discHits, 6)),
            scales = list(y = list(relation = "free")))
```
